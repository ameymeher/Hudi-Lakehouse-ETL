{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/12 15:25:59 WARN Utils: Your hostname, Ankitas-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.1.4 instead (on interface en0)\n",
      "24/09/12 15:25:59 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/12 15:25:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Reading source files\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the Source Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"source\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The count of the records is:  68\n"
     ]
    }
   ],
   "source": [
    "# Get the count of the records\n",
    "print(\"The count of the records is: \", df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+---------+------+---------+---------+--------+-------------------+----------------+------------+----------------+\n",
      "| Op| replicadmstimestamp|invoiceid|itemid| category|    price|quantity|          orderdate|destinationstate|shippingtype|        referral|\n",
      "+---+--------------------+---------+------+---------+---------+--------+-------------------+----------------+------------+----------------+\n",
      "|  I|2023-03-26 23:13:...|     9621|    29|Household|46.000000|       1|2016-04-17 05:30:00|              IN|        Free|           Other|\n",
      "|  I|2023-03-26 23:13:...|     4023|    80|   Office|18.000000|       4|2016-04-01 05:30:00|              ND|       3-Day|           Other|\n",
      "|  I|2023-03-26 23:13:...|    11369|    56|   Office|37.000000|       1|2016-06-01 05:30:00|              NH|       2-Day| Repeat Customer|\n",
      "|  I|2023-03-26 23:13:...|    10502|     5|  Kitchen|22.000000|       3|2016-07-02 05:30:00|              MT|       3-Day| Repeat Customer|\n",
      "|  I|2023-03-26 23:13:...|    12542|    55|   Garden|12.000000|       3|2016-09-23 05:30:00|              SC|        Free|       Online Ad|\n",
      "|  I|2023-03-26 23:13:...|     4465|    52|   Office|58.000000|       4|2016-12-10 05:30:00|              VA|       2-Day|       Online Ad|\n",
      "|  I|2023-03-26 23:13:...|     1069|    28|  Kitchen|74.000000|       3|2016-02-17 05:30:00|              WY|        Free| Repeat Customer|\n",
      "|  I|2023-03-26 23:13:...|     7867|    54|   Office|89.000000|       3|2016-03-28 05:30:00|              MN|       3-Day|           Other|\n",
      "|  I|2023-03-26 23:13:...|     3712|     3|  Kitchen|11.000000|       3|2016-01-23 05:30:00|              IL|        Free|           Other|\n",
      "|  I|2023-03-26 23:13:...|    11038|    63|Household|57.000000|       3|2016-02-11 05:30:00|              MD|       3-Day|       Online Ad|\n",
      "|  I|2023-03-26 23:13:...|     9543|    78|  Kitchen|31.000000|       1|2016-12-16 05:30:00|              MI|        Free|Friend/Colleague|\n",
      "|  I|2023-03-26 23:13:...|     7236|     7|   Office|27.000000|       3|2016-05-04 05:30:00|              SD|       3-Day|Friend/Colleague|\n",
      "|  I|2023-03-26 23:13:...|     8766|    82|  Kitchen|73.000000|       3|2016-04-26 05:30:00|              AL|        Free|Friend/Colleague|\n",
      "|  I|2023-03-26 23:13:...|    15059|    78|   Garden|95.000000|       4|2016-10-26 05:30:00|              NH|        Free|           Other|\n",
      "|  I|2023-03-26 23:13:...|    12763|    61|Household|96.000000|       2|2016-08-21 05:30:00|              WY|       2-Day|Friend/Colleague|\n",
      "|  I|2023-03-26 23:13:...|     9129|    85|   Office| 6.000000|       2|2016-08-27 05:30:00|              VA|       3-Day|       Online Ad|\n",
      "|  I|2023-03-26 23:13:...|     8867|    48|Household|83.000000|       3|2016-11-04 05:30:00|              VA|       2-Day| Repeat Customer|\n",
      "|  I|2023-03-26 23:13:...|     7463|    60|Household|90.000000|       2|2016-01-21 05:30:00|              LA|       3-Day|Friend/Colleague|\n",
      "|  I|2023-03-26 23:13:...|    14990|    95|   Garden|73.000000|       2|2016-07-10 05:30:00|              HI|       3-Day|Friend/Colleague|\n",
      "|  I|2023-03-26 23:13:...|    14828|    12|  Kitchen|84.000000|       1|2016-09-24 05:30:00|              NE|       3-Day| Repeat Customer|\n",
      "+---+--------------------+---------+------+---------+---------+--------+-------------------+----------------+------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Op: string (nullable = true)\n",
      " |-- replicadmstimestamp: string (nullable = true)\n",
      " |-- invoiceid: integer (nullable = true)\n",
      " |-- itemid: integer (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- price: decimal(28,6) (nullable = true)\n",
      " |-- quantity: integer (nullable = true)\n",
      " |-- orderdate: timestamp (nullable = true)\n",
      " |-- destinationstate: string (nullable = true)\n",
      " |-- shippingtype: string (nullable = true)\n",
      " |-- referral: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the invoiceid for the records where price > 30 and only get the counts\n",
    "df.filter(\"price > 30\").select(\"invoiceid\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "| category|total_count|\n",
      "+---------+-----------+\n",
      "|  Kitchen|         20|\n",
      "|   Office|         16|\n",
      "|Household|         16|\n",
      "|   Garden|         14|\n",
      "+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Group by the category and get the total counts and don't consideer the category with less than 10 records\n",
    "\n",
    "df.groupBy(\"category\").count().withColumnRenamed(\"count\",\"total_count\").filter(\"total_count > 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+----------+\n",
      "| category|    price|row_number|\n",
      "+---------+---------+----------+\n",
      "|   Garden|95.000000|         1|\n",
      "|   Garden|92.000000|         2|\n",
      "|   Garden|85.000000|         3|\n",
      "|   Garden|84.000000|         4|\n",
      "|   Garden|73.000000|         5|\n",
      "|   Garden|73.000000|         6|\n",
      "|   Garden|69.000000|         7|\n",
      "|   Garden|66.000000|         8|\n",
      "|   Garden|60.000000|         9|\n",
      "|   Garden|46.000000|        10|\n",
      "|   Garden|34.000000|        11|\n",
      "|   Garden|24.000000|        12|\n",
      "|   Garden|12.000000|        13|\n",
      "|   Garden| 9.000000|        14|\n",
      "|Household|96.000000|         1|\n",
      "|Household|90.000000|         2|\n",
      "|Household|88.000000|         3|\n",
      "|Household|83.000000|         4|\n",
      "|Household|80.000000|         5|\n",
      "|Household|68.000000|         6|\n",
      "+---------+---------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ranking the records based on the category and price\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "from pyspark.sql.functions import desc\n",
    "\n",
    "#orderby descending order\n",
    "windowSpec = Window.partitionBy(\"category\").orderBy(desc(\"price\"))\n",
    "\n",
    "# Add the row_number to the dataframe\n",
    "df = df.withColumn(\"row_number\", row_number().over(windowSpec))\n",
    "\n",
    "# Show the category, price and row_number\n",
    "df.select(\"category\", \"price\", \"row_number\").orderBy(\"category\", desc('price')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|      68|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the count by executing a SQL query\n",
    "df.createOrReplaceTempView(\"source_data\")\n",
    "sqlDF = spark.sql(\"SELECT COUNT(*) FROM source_data\")\n",
    "sqlDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|      54|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlDF = spark.sql(\"SELECT count(*) FROM source_data where price > 20\")\n",
    "sqlDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------+-------+\n",
      "|           col_name|    data_type|comment|\n",
      "+-------------------+-------------+-------+\n",
      "|                 Op|       string|   null|\n",
      "|replicadmstimestamp|       string|   null|\n",
      "|          invoiceid|          int|   null|\n",
      "|             itemid|          int|   null|\n",
      "|           category|       string|   null|\n",
      "|              price|decimal(28,6)|   null|\n",
      "|           quantity|          int|   null|\n",
      "|          orderdate|    timestamp|   null|\n",
      "|   destinationstate|       string|   null|\n",
      "|       shippingtype|       string|   null|\n",
      "|           referral|       string|   null|\n",
      "|         row_number|          int|   null|\n",
      "+-------------------+-------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the schema using the SQL query\n",
    "sqlDF = spark.sql(\"DESCRIBE source_data\")\n",
    "sqlDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the spark session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
